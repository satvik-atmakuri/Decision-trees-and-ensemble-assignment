# Decision-trees-and-ensemble-assignment

## Overview
This repository contains implementations of popular ensemble learning methods and boosting techniques written from scratch in Python. Each algorithm is demonstrated in Colab notebooks with detailed explanations and experiments.

### Algorithms Implemented
1. **Gradient Boosting Machine (GBM)**: Classic GBM written from scratch.
2. **Random Forest**: An ensemble of decision trees using bootstrap aggregation.
3. **AdaBoost**: A boosting algorithm that adjusts weights iteratively.
4. **Decision Trees**: Implemented with CART or ID3 algorithm.
5. **Showcase**: Demonstrating classifiers, regressors, and ranking models:
   - **Classifiers**: XGBoost, CatBoost, LightGBM, Random Forest, AdaBoost, Decision Trees.
   - **Regressors**: XGBoost, CatBoost, LightGBM.
   - **Ranking**: XGBoost, CatBoost, LightGBM.


## Colab Links:
- [GBM](https://docs.google.com/presentation/d/19j3wC-8_cz41CIm88F6kOFU8ys7zVcRfaBw6SImAeWc/edit#slide=id.ga2af525914_0_6955)
- [Random Forest](https://github.com/veb-101/Machine-Learning-Algorithms/blob/master/Random%20Forest/random_forest.ipynb)
- [AdaBoost](https://github.com/veb-101/Machine-Learning-Algorithms/tree/master/Boosting%20-%20AdaBoost)
- [Decision Trees](https://github.com/veb-101/Machine-Learning-Algorithms/tree/master/Decision%20Trees)

## Youtube Video:
- [Video Link](www.youtube.com)
