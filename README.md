# Decision-trees-and-ensemble-assignment

## Overview
This repository contains implementations of popular ensemble learning methods and boosting techniques written from scratch in Python. Each algorithm is demonstrated in Colab notebooks with detailed explanations and experiments.

### Algorithms Implemented
1. **Gradient Boosting Machine (GBM)**: Classic GBM written from scratch.
2. **Random Forest**: An ensemble of decision trees using bootstrap aggregation.
3. **AdaBoost**: A boosting algorithm that adjusts weights iteratively.
4. **Decision Trees**: Implemented with CART or ID3 algorithm.
5. **Showcase**: Demonstrating classifiers, regressors, and ranking models:
   - **Classifiers**: XGBoost, CatBoost, LightGBM, Random Forest, AdaBoost, Decision Trees.
   - **Regressors**: XGBoost, CatBoost, LightGBM.
   - **Ranking**: XGBoost, CatBoost, LightGBM.


## Colab Links:
- [GBM](https://colab.research.google.com/drive/1any9shFJQuLAuqyD43BDol6q2MQyc1ph?usp=sharing)
- [Random Forest](https://colab.research.google.com/drive/1aZeZYJIRr3Q1FWvoJEIDuTH_WkNq9zvi?usp=sharing)
- [AdaBoost](https://colab.research.google.com/drive/1ibt4Av0Gu9l5qEpLXXFjiblDqDbZXbJW?usp=sharing)
- [Decision Trees](https://colab.research.google.com/drive/12nK0LoOoQbYiMtTtN9FquBtNGm6s56Xb?usp=sharing)

## Youtube Video:
- [Video Link](www.youtube.com)
